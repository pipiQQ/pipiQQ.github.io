---
layout:     post
title:      "软件3.0——智能软件开发时代"
subtitle:   "软件3.0"
date:       2026-01-16 20:40:00
author:     "伊塔玛·弗里德曼"
catalog: false
published: true
header-style: text
tags:
  - 软件
---

# 软件3.0——智能软件开发时代

2022年5月3日

软件 2.0 正在彻底改变我们开发软件的方式，尽管这部分软件虽然意义重大但规模较小；而软件 3.0 技术栈将带领我们进入人人都能使用的无处不在的智能软件开发时代。

按回车键或点击查看完整尺寸的图片

![](https://miro.medium.com/v2/resize:fit:1050/1*IKoQfDTOf-DOnddtzCb2JA.jpeg)

照片由[Andrea De Santis](https://unsplash.com/@santesson89?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)在[Unsplash上拍摄](https://unsplash.com/s/photos/robot-code?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)

本文“站在巨人的肩膀上”，灵感来源于世界各地优秀人士的文章和观点，主要参考了 Andrej Karpathy 的博文“软件 2.0”[ [1](https://karpathy.medium.com/software-2-0-a64152b37c35) ]。让我们先引用[1]（略作修改）：

> 我们都熟悉的“经典软件栈”是**软件1.0时代**的核心——它由程序员使用Python、C++、JS、CSS等语言编写。它包含发送给编译器/解释器的显式（声明式或命令式）指令。程序员通过编写每一行代码/指令，在程序空间中确定一个具有特定预期行为的点。
> 
> 相比之下，**软件 2.0**使用更加抽象、对人类不友好的语言编写，例如神经网络的权重。由于权重数量庞大（典型的神经网络可能有数百万个权重），因此编写这类代码不需要任何人参与。

最新的突破使我们能够展望**软件3.0时代**。  
在软件3.0中，程序员提供一组指令和一个数据集，用于定义程序的预期行为。然后，人工智能代理会获取这些指令和数据集，并生成程序。这一创建过程包括代理生成程序员可读的代码以及训练神经网络模型。

生成的程序员可读代码可以是 SW 1.0 和 SW 2.0 的语言和语法，例如应用程序前端的 Javascript 代码或带有神经网络模型定义的 Python 代码。

指令可以采用多种形式。例如，它们可以是网页应用程序设计或线框图文件，并附有相应的应用程序用户故事（以自然语言或其他形式呈现）。再举一例，指令可以是针对对话式人工智能机器人预期输出的一系列规则和要求，以自然语言给出，旨在进一步影响机器人的行为，以补充（或对比）数据集带来的偏差。

按回车键或点击查看完整尺寸的图片

![](https://miro.medium.com/v2/resize:fit:1050/1*s2zzhTphoEBUNi_b7832Ug.jpeg)

图 1. 软件 1.0、2.0 和 3.0 开发范式和技术栈

为了更清楚地说明这个类比，在 SW 1.0 中，人工设计的源代码（例如，一些 .cpp 文件）被编译成一个二进制文件，从而完成有价值的工作。

在 SW 2.0 中，源代码通常包括：1) 具有业务逻辑、I/O 控制和数据预/后处理的固定“经典”代码；2.a) 定义大部分所需行为的数据集；2.b) 具有许多待填充细节（权重）的神经网络 (NN) 架构；以及 3) 用于填充 NN 权重和编译最终神经网络的代码。

在SW 3.0中，业务逻辑、I/O控制以及数据预处理/后处理代码部分甚至全部由AI代理在优化过程中生成。SW  
3.0的表达能力（即程序空间）涵盖了SW 1.0和SW 2.0的程序空间，因为它能够生成两者的输出。也就是说，SW 3.0协议栈生成的程序可以包含来自SW 1.0和SW 2.0协议栈的任何代码行、数据点和神经网络层的知识或计算能力。

按回车键或点击查看完整尺寸的图片

![](https://miro.medium.com/v2/resize:fit:1050/0*ddZlcuzZFjQu743E)

图 2. 程序空间以及软件 1.0、2.0 和 3.0 的开发过程。（原始出处：[1]）

## 范式转变

在当今大多数基于机器学习的实际应用中（截至2022年4月），神经网络架构和训练系统正日益标准化，趋于商品化，因此大部分活跃的“软件2.0开发”都集中在对已标注数据集进行整理、扩充、处理和清洗上。（当然，还有其他精彩的机器学习方法！例如，自监督技术正在不断改进，因此所需的标注工作量正在减少。）这从根本上改变了我们迭代软件的编程范式（软件1.0→软件2.0），因为团队被分为三类：

- 2.0 程序员（例如数据/机器学习工程师和数据科学家）负责收集和清理数据集，并运行训练/优化过程。
- 少数 1.0 程序员（例如包括 MLOPs 工程师）负责维护和迭代相关的训练代码基础设施、分析、可视化和标注界面。
- 另一组 1.0 级程序员负责开发应用程序的用户界面 (UI)、业务逻辑中的非统计部分、工作流程等等……

在大多数情况下，整个应用程序逻辑的很大一部分实际上是由 SW1.0 程序员手动编写的，并且是“固定”的（即，大部分逻辑和代码不是机器在优化过程中建议的）。

变革之风。得益于最新的大型语言模型（LLM）技术和训练方案，我们看到编程范式发生了新的转变，代码由智能代理（例如 GitHub Co-pilot [ [3 ]）](https://copilot.github.com/)*编写*（或建议） 。当 SW 3.0 成熟后，大多数程序员将使用 SW 3.0 技术栈，因为它应该能够覆盖大部分程序空间（与 SW 2.0 技术栈相比；参见上图 2）。[](https://copilot.github.com/)

## 这是一个持续的过渡过程（SW 1.0 → 2.0 → 3.0）

视觉识别、语音识别、语音合成、机器翻译、游戏代理，甚至数据库缓存/索引/查询。

在上述各个领域，我们都已取得了一些改进。过去几年，我们放弃了使用 SW 1.0 技术栈编写显式代码来彻底解决复杂问题的做法，转而过渡到 2.0 技术栈。

最近，我们看到代码自动完成/建议的技术和产品有了显著的改进，例如 Codex [ [2 ] 及其在 Github Co-pilot [](https://openai.com/blog/openai-codex/) [3](https://copilot.github.com/) ]中的实现（之前也有过类似的尝试，例如 TabNine [ [17](https://github.com/codota/TabNine) ]）。

许多用户表示使用这些工具后感觉非常神奇，但也有用户反映，其提供的代码并非总是准确的。例如，可以参考 Jeremy Howard 的评论文章“GitHub Copilot 是福是祸？”[ [4](https://www.fast.ai/2021/07/19/copilot/) ]。  
人们对该领域的兴趣正在迅速增长，新的自动错误发现解决方案也正在开发中[ [5](https://www.microsoft.com/en-us/research/blog/finding-and-fixing-bugs-with-deep-learning/) ]。

在底层，语言学习模型（例如 GPT-3 [ [6](https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system) ]）提供代码建议功能。语言学习模型并不局限于以自然语言作为输入和输出。例如，它们可以将自然语言请求转换为 SQL、Python 或其他兼容多种实用框架和服务 API 的语言。

[我们以AI21Labs的最新成果Jurassic-X[ 7](https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system) ]为例（见下图3）。他们的团队将LLM（名为Jurassic-1）与一组“头”（即多功能组件）配对，每个“头”都作为专家，在特定领域或主题上更加精准，例如进行计算或参与规划。这巧妙地展示了一种克服当代生成模型某些缺陷的方法。

作者写道：“MRKL 系统由一组可扩展的模块（在 Jurassic-1 模型之上）组成，我们称之为‘专家’，还有一个路由器，可以将每个传入的自然语言输入路由到能够最好地响应该输入的模块。”

按回车键或点击查看完整尺寸的图片

![](https://miro.medium.com/v2/resize:fit:1050/0*fVWa5sp8SswNSHfe)

图 3. 侏罗纪 X 型示意图。（来源：[ [7](https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system) ]）

再举一个例子，可以通过提供不同的指令（&|提示）来调整GPT-3[ [6 ]。](https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system)

一些从业者已经指出，如今的机器学习工作包括向 GPT-3 或类似模型提供指令（或提示）。例如，参见 L2P（学习提示）[ [16](https://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html?m=1) ]、提示视觉语言模型 [ [18](https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model) ] 或以下推文。

（提示是对 LLM 输入查询的重新表述，通常是插入在查询开头的一段文本。其目的是引导预训练的 LLM 根据所需的格式和行为提供输出。）

## 软件3.0的局限性

2.0 版本协议栈也存在一些自身的缺点。优化完成后，我们的程序会构建出运行良好的大型网络，但很难解释其运行机制。

2.0 堆栈可能会以不直观且令人尴尬的方式失败 [ [8](https://blog.openai.com/adversarial-example-research/) ]，或者更糟的是，它们可能会“悄无声息地失败”，例如，通过在其训练数据中悄悄地采用偏差，这可能很难正确识别、分析和解决。

我们仍在探索该栈的一些奇特性质。例如，对抗样本[ [9](https://blog.openai.com/adversarial-example-research/) ]和攻击[ [10](https://github.com/yenchenlin/awesome-adversarial-machine-learning) ]的存在凸显了该栈的非直观性。

以上这些限制也适用于 3.0 版本。

更具体地说，对于 SW 3.0，由于代码是由统计模型（前面提到的 AI 代理）生成的，它也可能生成有缺陷且未优化的代码（类似于人类？），即使以人类/程序员可读的语言提供，这些缺陷也可能被忽略。

## 软件3.0的优势

为什么我们应该选择SW 3.0而不是SW 2.0？

[

![成为会员](https://miro.medium.com/v2/da:true/resize:fit:0/60026f4340686a391639ac58864da18070aa773cea45de6e55fa47fd56bfdb74)

](https://medium.com/plans?source=upgrade_membership---post_li_non_moc_upsell--acd3cafe6cd7---------------------------------------)

**更大的程序空间**。神经网络及其推理引擎实际上并不适合表达和执行所有可以用“经典”编程语言实现的行为。[2022年4月]

**确定性模型和统计模型的结合**。确定性行为编码在代码中，统计性行为编码在神经网络中。

**可解释性和可理解性**。在SW 3.0中，使用神经网络来表达非统计程序行为的动力可能有所降低，因为自动将所需行为转换为程序员可读的代码已成为可能，而这种代码可能比神经网络更容易被人类理解。

**适应性**。对程序员来说，修复或修改代码比调整神经网络的权重要容易得多。

**更多的人可以成为程序员**。在软件3.0中，应用程序整体中更大比例的代码以自然语言指令的形式表达，这使得扩大程序员队伍变得更加可行。  
这可能会对社会和企业产生巨大的影响。目前，程序员的供需严重不匹配，尽管在线教育资源日益丰富，但软件1.0和软件2.0技术栈都设置了较高的准入门槛。

**开发速度加快**。一旦将自动化引入软件应用程序构建的确定性和统计性方面，软件程序的编写速度就能更快。

**这是迈向通用人工智能的一步**。:)……更多内容请参见最后一节。

## 使用 3.0 技术栈进行编程

软件 1.0 是我们自己编写的代码。软件 3.0 则是通过优化过程编写的代码，该过程以评估标准（例如“最符合指令和数据所给出的预期行为”）为指导。任何程序并非显而易见，但可以反复评估其性能的场景（例如——你是否正确分类了一些图像？你是否赢得了编程比赛？）都可能经历这种转变，因为优化过程很可能找到比普通人编写的代码好得多的代码。

考虑到这种转变，我们也将会看到新的自动化（智能）测试工具和流程，这是合乎逻辑的。

与软件 1.0 和软件 2.0 相比，软件 3.0 技术栈中的自动化测试可能会变得更加重要，原因有很多。例如：1）程序员（包括经验不足的程序员）将能够完成更多工作；2）应用程序和程序将更加动态，基于统计的程序将驱动应用程序的更多部分。

例如，借助SW 3.0，开发能够根据用户需求调整布局、结构和内容的网站和移动应用将变得更加容易，同时还可以引入智能聊天机器人来辅助导航、实现自动化操作并提升用户体验。这可能会使手动测试变得不切实际。取而代之的是，测试用的AI代理将模拟各种不同类型的用户使用网站或应用的行为。

## 可从软件 3.0 中受益的应用示例

思考（和着手）以上这些事情就已经让我非常兴奋了。但想到我们可以利用这项技术做什么，以及它将如何发展，就让我无比兴奋。

**网页设计和开发**——将使产品经理能够使用简单的图形用户界面对网页或移动应用程序进行有意义的更改或建议，然后人工智能代理将相应地将相关的代码版本发布到程序员的代码库中，供他们审查和批准。

**无代码平台**——将更加灵活。

**下一代 RPA** — 将自动化许多工作流程和后台任务[12, 13]。

**数据工具**——将普及并被大多数知识工作者使用。这包括数据收集[ [15](https://openai.com/blog/webgpt/) ]，

**测试工具**将变得极其智能、自动化且信息丰富。这将极大地改进目前手动测试的方式（市场规模超过100亿美元？）。这不仅仅是“锦上添花”，开发智能测试工具来应对软件3.0带来的复杂性将成为必然之举。

**研究工具——**可以减轻研究人员的大部分研究工作，例如进行自动化文献综述。例如，这可以包括自动化网络爬虫[ [15](https://openai.com/blog/webgpt/) ]。

**还有很多其他**建议——*欢迎在评论区留言。*

## 总结与展望

SW 3.0 是实现通用人工智能 (AGI) 的框架吗？  
我看到了正反两方面的观点 [ [12](https://techcrunch.com/2022/04/26/2304039/) ]。

在 SW 3.0 中，新程序的期望行为是通过类似自然语言的指令和数据提供给 AI 代理的，AI 代理反过来输出一个由程序员可读代码和具有期望行为的神经网络编译而成的 AI 程序：

> 指令 + 数据 → AI 代理 → 代码 + 神经网络

那么，想象一下这样一个具体的应用场景：“指令+数据”表达了对更优秀的AI代理的期望行为？  
因此，

> 指令 + 数据 → AI 代理 → 改进型 AI 代理

问题 1）这种“指令+数据”会是什么样子？我们能否通过一些简单或复杂的模拟来创建它？  
问题 2）然后，我们能否反复运行这个过程？

在进一步探讨这个神奇的人工智能循环并辩论其实现机制之前，即使是更简单的设置也可能产生奇效。例如，DeepMind 发布的 AlphaCode [ [11](https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf) ]，它是 SW 3.0 的一个实例。AlphaCode 在 Codeforces 举办的编程竞赛中名列前 54%，而这些竞赛的参赛数据晚于其训练数据的发布时间。AlphaCode：

> 指令 + 数据 → 人工智能代理 → 赢得编程竞赛

“在这些竞赛中脱颖而出所需的解决问题的能力超出了现有人工智能系统的能力范围。然而，通过将大规模Transformer模型（最近已展现出生成代码的良好能力）的进步与大规模采样和滤波相结合，我们在能够解决的问题数量方面取得了显著进展，”DeepMind写道。

AlphaCode 中使用的特定设置足以启动神奇的 AI 循环吗？可能不足以，因为目前的编程任务并不包括创建改进型 AI 代理的任务。

未来几年，我们将看到大量的研究工作，以改进用于创建生成程序的 AI 代理的设置和学习方案。

无论采用何种方案，当 AlphaCode 跻身参与者前 1% 时，我预计它已经具备了颠覆性的力量。

此外，随着这些强大能力的出现，我相信我们将在以下领域看到更多的研究、需求和成就：

1）负责任且真实的AI[ [14](https://www.alignmentforum.org/posts/aBixCPqSnTsPsTJBQ/truthful-ai-developing-and-governing-ai-that-does-not-lie) ]  
2）智能软件测试、评估和监控  
3）高级数据分析

**软件3.0的**核心在于人与机器的紧密协作，共同打造智能软件。  
我们将看到软件3.0技术栈及相关开发流程的自下而上和自上而下两种发展路径。

**自下而上：**函数、类和功能将通过新引入的 IDE、代码管理、测试、代码生成和 SW 3.0 堆栈分析来生成。

**自上而下**：图形化和可编程应用程序界面将使用新推出的基于无代码/低代码软件 3.0 的平台生成。

最后一点：如果你正准备阅读 Karpathy 的原文，我建议你也阅读一下已发布的评论，看看你认为这些评论是否经得起时间的考验。

谢谢！

[1] https://karpathy.medium.com/software-2-0-a64152b37c35  
[2] [OpenAI Codex | OpenAI](https://openai.com/blog/openai-codex/)  
[3] [https://copilot.github.com/](https://copilot.github.com/)  
[4] [Redirect](https://www.fast.ai/2021/07/19/copilot/)  
[5] https://www.microsoft.com/en-us/research/blog/finding-and-fixing-bugs-with-deep-learning/  
[6] [Instruct GPT-3](https://openai.com/blog/instruction-following/)  
[7] https://www.ai21.com/blog/jurassic-x-crossing-the-neuro-symbolic-chasm-with-the-mrkl-system  
[8] [micer.vice 上关于偏差的文章](https://motherboard.vice.com/en_us/article/nz7798/weve-already-taught-artificial-intelligence-to-be-racist-sexist)  
[9] https://blog.openai.com/adversarial-example-research/  
[10] [GitHub - yenchenlin/awesome-adversarial-machine-learning: A curated list of awesome adversarial machine learning resources](https://github.com/yenchenlin/awesome-adversarial-machine-learning)  
[11] [AlphaCode](https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf)  
[12] [Adept aims to build AI that can automate any software process](https://techcrunch.com/2022/04/26/2304039/)  
[13] 一种基于数据驱动的计算机控制学习方法https://arxiv.org/pdf/2202.08137.pdf  
[14] [Truthful AI 文章](https://www.alignmentforum.org/posts/aBixCPqSnTsPsTJBQ/truthful-ai-developing-and-governing-ai-that-does-not-lie)  
[15] [WebGPT: Improving the factual accuracy of language models through web browsing | OpenAI](https://openai.com/blog/webgpt/)  
[16] https://ai.googleblog.com/2022/04/learning-to-prompt-for-continual.html?m=1  
[17] [GitHub - codota/TabNine: AI Code Completions](https://github.com/codota/TabNine)  
[18] https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model
